---
title: "reddit theme extraction"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook tryna recreate the python notebook we have which will then be integrated into a shiny webapp hosted on shinyapps.io.

In notebook form for ease of testing chunks at a time, will be consilidated into a script later.

Load data mining libs
```{r, warning=FALSE, message=FALSE}
library(tm)
library(SnowballC)
```

read in data. 
```{r}
data = read.csv('nba_2017_1-2017_1.csv')
```

pre-process (switch to lc, remove num, remove punc and stopwords, strip whitespace) for nmf
```{r}
library(tm)

samples = Corpus(VectorSource(data$X2))

samples = tm_map(samples, content_transformer(tolower))
samples = tm_map(samples, removeNumbers)
samples = tm_map(samples, removePunctuation)
samples = tm_map(samples, removeWords, c("the", "and", stopwords("english")))
clean =  tm_map(samples, stripWhitespace)
```

remove sparse terms / create tf-idf vector
```{r}
data_dtm = DocumentTermMatrix(clean, control = list(weighting = weightTfIdf))
data_dtm = removeSparseTerms(data_dtm, 0.95)
data_dtm
```

group by date (may need to do this AFTER nmf)
```{r}
m = as.matrix(data_dtm)
m = aggregate(m ~ X1, data, sum)
dates = m[,1]
m = m[,2:ncol(m)]
```

further reduce to 250 terms just for testing and do nmf (will use 1000 later, but now is too slow)
```{r}
library(NMF)
# default NMF algorithm
m_sorted = sort(colSums(m), decreasing = TRUE)

data_nmf = m[,names(m_sorted[1:250])]

res = nmf(data_nmf,10)
res
```

find top 10 words in each theme
```{r}
h = coef(res)
for (i in 1:length(h[,1])) {
  print(names(sort(h[i,], decreasing = TRUE)[1:10]))
}
```

generate a heatmap
```{r}
basismap(res,Rowv=NA,info=TRUE, labRow=dates)
```
